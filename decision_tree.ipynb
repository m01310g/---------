{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 의사 결정 트리: 트리 모델을 바탕으로 규칙을 세움, 마지막 노드에는 목적 변수\n",
    "- 마지막 리프 노드: 클래스/예측치\n",
    "- 상위 부모 노드: if-else 조건문(분할 속성: 부모 노드에 들어가는 조건)\n",
    "- 분할 속성의 기준: 정보 이득(엔트로피), 평준화된 정보 이득, 지니지수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 목표: feature과 목적 변수가 이산적인 범주형 변수인 상황의 알고리즘, 연속적인 변수인 상황에는 regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ID3 -> 엔트로피(반복적으로 데이터를 탑다운 방식으로 나누는 알고리즘)\n",
    "- 분포의 다양성 정도(정보량)를 정량적으로 표현한 값<br>\n",
    "-> 낮은 엔트로피 = 낮은 불확실성<br>\n",
    "-> 높은 엔트로피 = 높은 불확실성<br>\n",
    "- 측정 방법: Shannon의 공식 활용\n",
    "- 정보 이득: 불순도 -> 엔트로피를 활용하여 측정<br>\n",
    "-> (전체 엔트로피) - (속성별 엔트로피) = (속성별 정보 이득)<br><br>\n",
    "분할 속성을 선택할 때 너무 많은 속성으로 나누면 엔트로피 감소(일반화 능력 감소) -> penalty를 주어야 한다는 개념 추가 -> C4.5(값의 다양성 반영)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C4.5 -> ID3에서 분류 속성의 값이 다양할수록 불순도 감소 -> 정보 이득 증가\n",
    "- 정보 이득 측정 방식 평쥰화(SplitInfo) -> (정보 이득) / (속성의 그룹 엔트로피)\n",
    "- 다양한 속성 값을 가지면 SplitInfo가 매우 커져서 낮은 정보 이득 값\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CART(Classification and Regression Tree): 분류 속성을 결정하는 기준을 지니 지수로 개선, 이진 분할 실시\n",
    "#### 지니 지수\n",
    "- 경제학에서 소득의 불평등도 측정 시 사용하는 지표\n",
    "- 의사 결정 트리에서 각 속성의 불순도를 측정하는 방법\n",
    "- 지니 지수가 작으면 작을수록 불순도가 낮아짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 의사 결정 트리에서의 과대 적합\n",
    "- 데이터가 1개인 leaf node의 개수가 많다면 과대 적합(데이터를 잘 기억한 것과 똑같음)\n",
    "- leaf node의 불순도가 높다면 과소 적합\n",
    "- leaf node 개수, tree의 깊이, leaf node에서의 학습 데이터 개수 중요\n",
    "## -> 트리 가지치기: 의사 결정 트리의 마지막 노드의 개수를 지정해서 트리의 깊이 조정\n",
    "- 사전 가지치기: 학습 전에 leaf node의 개수 지정(sklearn에서 구현 가능)\n",
    "- 사후 가지치기: 학습 후에 leaf node의 개수 지정(sklearn에서 구현 불가)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 연속적인 값을 갖는 속성 분할\n",
    "- 모든 데이터를 기준점으로 하여 데이터 분할: 너무 많은 기준점 -> 과대 적합 발생/분류의 정확도 떨어짐\n",
    "- 통계적 수치로 중위값이나 4분위수를 기준점으로 분할: 과소 적합 가능성\n",
    "- 목적 변수의 값이 변할 때를 기준점으로 분할 -> 가장 elegance한 방법.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 회귀 트리: 목적 변수가 연속작인 값을 갖는 경우\n",
    "- 목적 변수가 이산적인 값을 갖는 경우에는 의사 결정 트리 사용\n",
    "- 분할의 기준이 되었던 정보 이득과 지니 지수가 분산으로 바뀜<br>\n",
    "-> 분산이 낮다 = 엔트로피가 작다<br>\n",
    "- 속성으로 분할된 그룹별 분산의 평균값 비교\n",
    "- 분산으로 분할 가지 결정<br>\n",
    "### 해당 그룹의 분기 시에 예측값은 학습 데이터들의 평균값으로 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
